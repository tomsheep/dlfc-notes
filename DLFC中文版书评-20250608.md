
# DLFC：一套深度学习的思维体操

Bishop的书总是常看常新。这是我第二次读《深度学习：基础与概念》（以下简称DLFC）这本书：去年我读过这本书的英文版，当时给我留下的最深印象，是书中对于机器学习领域几十年来的「变」与「不变」的深刻把握，用一个更高的视角去梳理出什么是这个领域的「基础」。

第二次读中文版，又有一番新的收获。盖因这一年中我自己的学识也有了一些进步，书中的许多「微言大义」，过去无法体会的更深切，此时也能读出一些新的认识。喜欢「精读」的读者，大概会喜欢这样的阅读体验，每一遍把玩都能发现新的细节，时间不仅不会被浪费，还能充分体验自己「成长」的乐趣。

## 一、导读：章节主线

在去年的书评里，我把DLFC和PRML做了逐章的对比，稍微窥探了一下Bishop眼中机器学习领域这若干年来的变化。

而这次的导读，我们就回归到 DLFC 这一本书上，看看这20章的篇幅是如何「连点成线」的。如果粗略地划分一下板块，这本书的大致是这样组织的：

- 概率基础：第1-3章
	- 其中「最大似然」、「密度估计」、「正则化」的部分需要读者格外重视，因为这些思想贯穿了整本书，几乎是无处不在的。
- 深度学习基础：第4-9章
	- 用神经网络的视角，去讲解机器学习领域的基础概念：模型结构、误差函数、梯度下降、反向传播等等。
	- 其中「归纳偏置」的思想非常重要，可以说是学习后半部分各种具体模型的必备视角。
- 结构化学习：第10-13章
	- 这部分介绍了几种重要的深度学习算法，CNN、Transformer、图神经网络等。
	- 但 Bishop 的书向来不为了介绍某种「具体算法」，他这样安排是想阐述「结构化学习」这个共通的思想，上述几种模型都是针对不同的「结构化数据」、引入不同的「归纳偏置」的产物。
- 非线性潜变量学习：第14-20章
	- 这个视角囊括了几种现代的生成模型：GAN、VAE、流模型、扩散模型等。
	- 读者需要重点关注一下 ELBO 和 EM算法，是理解这部分的「钥匙」，几乎应用在了每个模型的推导中。

## 二、高观点：无用之用

我很喜欢Bishop写作方式的一个原因，是他经常会插入一些非常「不实用」的话题，而且长篇大论地展开。对那些相对「常用」的知识，反而惜墨如金，寥寥几句点出精髓。这恰恰也是很多人不喜欢他的书的原因。

但就是这些「无用」的东西，非常有启发性，能够让你去思考「为什么」。比如：

- 介绍基础的分类问题时，先给你插入一段如何用「最小二乘法」做分类——在现实中没人会这么干，但为什么不这么做呢？思考一下这个问题，看似无用，但实际上已经有所得了。
- 介绍 K近邻方法时，他洋洋洒洒地推导了大量的公式，不是单单为了介绍这一个算法，而是想告诉你，K近邻本质是一种「密度估计」，和直方图、核密度方法是同根同源的。这样一套下来，你从中得到的，远比学习了几个具体算法要大得多。
- 介绍激活函数时，他用一个更通用的视角，推导了整个「指数分布簇」的目标形式，点出了误差函数和输出层激活函数的内在配对关系。看似复杂绕远，但实际上更加简洁深刻。
- 介绍Transformer时，他没有像大多数教材一样直接给出Transformer的设计，而是一步一步地，从没有参数矩阵的「注意力」机制开始，逐步引入非线性、不对称性等等，让读者看清每一个细节设计的「原因」。

这种例子比比皆是。《高观点下的基础数学》的作者Klein认为， **基础数学的教师应该站在高等数学的视角来审视教学，只有观点高了，事物才能显得明了而简单。** 在机器学习领域的教材中，Bishop无疑是「高观点」教学的践行者。

## 三、反复阅读：螺旋上升

同时，我必须要承认，这不是一本适合初学者的书，入门级的读者很容易被书中大量的数学推导劝退，找不到抓手，当年我学习PRML时也有类似的痛苦。

可以说，它对学习者提出了更高的要求：

- 它要求你**反复**学习，如切如磋，如琢如磨，不断地提升自己的认知；
- 它要求你**主动**学习，不囿于「是什么」，而且要思考「为什么」；
  
惟其如此，你才能体会这本书「思维体操」的乐趣。


## 四、勘误

在这次的阅读中，也发现了一些书中的细节问题，有些是原书中的疏忽，有些是翻译时的纰漏，还有些则是我个人的强迫症。

我戏称是开启了「高清纠错」模式，遇到可疑的地方就会停下来多思考一下，有时候还是一种乐趣。

我把自己发现的一些可能有问题的地方整理了一下，也分享给各位读者。


